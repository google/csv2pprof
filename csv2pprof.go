package csv2pprof

import (
	"encoding/csv"
	"fmt"
	"io"
	"strconv"
	"strings"

	"github.com/google/pprof/profile"
)

// Convert CSV from in, to gzip-compressed pprof wire format on out.
func ConvertCSVToCompressedPprof(in io.Reader, out io.Writer) error {
	p, err := ConvertCSVToPprof(in)
	if err != nil {
		return err
	}
	if err := p.Write(out); err != nil {
		return fmt.Errorf("failed writing profile: %v", err)
	}
	return nil
}

type pprofBuilder struct {
	p *profile.Profile

	// Save functions to reuse. Index by frame string.
	functions map[string]*profile.Function
	// The next function should have the number after this as it's ID
	lastFunctionID uint64

	// Save locations to reuse. Index by frame string.
	locations map[string]*profile.Location
	// The next location should have the number after this as it's ID
	lastLocationID uint64
}

func newPprofBuilder(p *profile.Profile) *pprofBuilder {
	p.Comments = []string{"Generated by csv2pprof"}
	return &pprofBuilder{
		p:         p,
		functions: map[string]*profile.Function{},
		locations: map[string]*profile.Location{},
	}
}

// Finds or creates a profile.Function for the given frame in the Profile. Reuses cached Functions.
func (b *pprofBuilder) function(frame string) *profile.Function {
	if function, ok := b.functions[frame]; ok {
		return function
	}
	b.lastFunctionID++
	function := &profile.Function{
		ID:   b.lastFunctionID,
		Name: frame,
	}
	b.functions[frame] = function
	b.p.Function = append(b.p.Function, function)
	return function
}

// Finds or creates a profile.Function for the given frame in the Profile. Reuses cached Locations.
func (b *pprofBuilder) location(frame string) *profile.Location {
	if location, ok := b.locations[frame]; ok {
		return location
	}
	b.lastLocationID++
	location := &profile.Location{
		ID: b.lastLocationID,
		Line: []profile.Line{
			{Function: b.function(frame)},
		},
	}
	b.p.Location = append(b.p.Location, location)
	return location
}

func ConvertCSVToPprof(in io.Reader) (*profile.Profile, error) {
	r := csv.NewReader(in)
	p := &profile.Profile{}
	stackCol := -1

	b := newPprofBuilder(p)

	for i := 0; ; i++ {
		record, err := r.Read()
		if err == io.EOF {
			break
		}
		if err != nil {
			return nil, fmt.Errorf("error reading CSV: %v", err)
		}

		if i == 0 {
			// read headers
			p.SampleType, stackCol, err = readHeaders(record)
			if err != nil {
				return nil, err
			}
			continue
		}

		// read non-headers
		sample := profile.Sample{}
		for col, value := range record {
			if col == stackCol {
				frames := strings.Split(value, ";")
				for i := range frames {
					// The leaf has to be first. So reverse the line.
					// https://github.com/google/pprof/blob/eeec1cb781c311df467fabdc8c384fa52e91bc65/proto/profile.proto#LL110C26-L110C26
					frame := frames[len(frames)-i-1]
					location := b.location(frame)

					sample.Location = append(sample.Location, location)
				}
				continue
			}

			samples, err := strconv.ParseInt(value, 10, 64)
			if err != nil {
				return nil, fmt.Errorf("on line %v, couldn't parse number: %v", i+1, err)
			}
			sample.Value = append(sample.Value, samples)
		}
		p.Sample = append(p.Sample, &sample)
	}
	return p, nil
}

func readHeaders(headers []string) (sampleTypes []*profile.ValueType, stackCol int, err error) {
	stackCol = -1
	for col, header := range headers {
		if header == "stack" {
			stackCol = col
			continue
		}
		valueType := profile.ValueType{}
		if strings.Contains(header, "/") {
			slash := strings.LastIndex(header, "/")
			valueType.Type = header[:slash]
			valueType.Unit = header[slash+1:]
		} else {
			valueType.Type = header
			valueType.Unit = "count"
		}
		sampleTypes = append(sampleTypes, &valueType)
	}
	if stackCol == -1 {
		return nil, 0, fmt.Errorf("expected \"stack\" in CSV header row, got: %q", headers)
	}
	if len(sampleTypes) == 0 {
		return nil, 0, fmt.Errorf("expected columns with weights in CSV header row, got %q", headers)
	}
	return sampleTypes, stackCol, nil
}
